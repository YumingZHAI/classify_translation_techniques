# original: annotators = tokenize, ssplit, pos, lemma, ner, parse, dcoref

file = en_noID.txt

# default is "xml", text, json, conll, conllu(in columns), serialized

# this output format can be used to extract constituency and dependency parsing features 
outputFormat = text
output.constituencyTree = oneline
outputExtension = .oneLine

# known tree styles to edu.stanford.nlp.trees.TreePrint:  
# oneline, penn, latexTree, xmlTree, words, wordsAndTags, rootSymbolOnly
# dependencies, typedDependencies, typedDependenciesCollapsed, collocations, semanticGraph, 
# conllStyleDependencies, conll2007.

##output.dependencyTree=dependencies

# this output format can be used to extract POS and lemma features for my classifier
#outputFormat = conll
#output.columns = word,pos,lemma
#output.prettyPrint = false

outputDirectory = ./for_classifier
# outputExtension = 
#replaceExtension = true 
#If youâ€™d rather replace the extension with the -outputExtension, pass the -replaceExtension flag. This will result in filenames like input.xml instead of input.txt.xml (when given input.txt as an input file).

#noClobber = true 
#Skipping english.txt: output file /Users/yumingzhai/translation/current-working/stanford-corenlp-full-2018-10-05/testOutput/english.txt.xml as it already exists.  Don't use the noClobber option to override this.

# should explicit both parse and depparse
annotators = tokenize, ssplit, pos, lemma, parse, depparse

#, parse, depparse

#tokenize.language = en
tokenize.whitespace = true

# don't leave empty lines in the file
ssplit.eolonly = true 
#ssplit.newlineIsSentenceBreak = always 

# encoding =        UTF-8 is by default 

# by default: 
# pos.model = edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger

# parse.model = edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz

# depparse.model = edu/stanford/nlp/models/parser/nndep/english_UD.gz

#----------------------------official English properties: 

#annotators = tokenize, ssplit, pos, lemma, ner, depparse, coref

#tokenize.language = en

# Some other annotators are also available for English and can be optionally loaded, e.g.:
# annotators = tokenize, ssplit, pos, lemma, truecase

# This is an example of the "full" pipeline, though there are even more annotators than this:
# annotators = tokenize,cleanxml,ssplit,pos,lemma,ner,parse,depparse,coref,natlog,openie,kbp,entitylink,sentiment,quote

# Options like the ones below are being set as defaults in code

# pos.model = edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger

# ner.model = edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz,\
#             edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz,\
#             edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz

# sutime.rules = edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,\
# edu/stanford/nlp/models/sutime/english.holidays.sutime.txt

# ner.fine.regexner.mapping =
# "ignorecase=true,validpospattern=^(NN|JJ).*,edu/stanford/nlp/models/kbp/regexner_caseless.tab;\
#  edu/stanford/nlp/models/kbp/regexner_cased.tab"
# ner.fine.regexner.noDefaultOverwriteLabels = CITY

# parse.model = edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz

# depparse.model = edu/stanford/nlp/models/parser/nndep/english_UD.gz

# coref.algorithm = statistical
# coref.md.type = dependency
# coref.statistical.rankingModel = edu/stanford/nlp/models/coref/statistical/ranking_model.ser.gz
